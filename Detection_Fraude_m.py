# -*- coding: utf-8 -*-
"""Detection_Fraude_m.py"""

# Packages (tous les imports du script original)
!pip install loguru
from pathlib import Path
import dill
import matplotlib.pyplot as plt
import missingno as msno
import numpy as np
import pandas as pd
# import pendulum # Non utilis√© directement dans le code fourni, peut √™tre comment√©
import plotly.graph_objects as go
import plotly.express as px
import seaborn as sns
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline as imb_Pipeline
from loguru import logger
from sklearn import set_config
from sklearn.compose import make_column_transformer, ColumnTransformer
from sklearn.dummy import DummyClassifier
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (confusion_matrix,
                             classification_report,
                             ConfusionMatrixDisplay,
                             roc_auc_score,
                             accuracy_score,
                             precision_score,
                             recall_score,
                             f1_score,
                             RocCurveDisplay,
                             PrecisionRecallDisplay,
                            )
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.neighbors import KNeighborsClassifier
from sklearn.pipeline import Pipeline # sklearn.pipeline.Pipeline
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OrdinalEncoder, OneHotEncoder
# from ucimlrepo import fetch_ucirepo, list_available_datasets # Non utilis√©, peut √™tre comment√©
# from yellowbrick.classifier import DiscriminationThreshold # Non utilis√©, peut √™tre comment√©


set_config(display='diagram')
pd.set_option("display.max_columns", None)

"""# Data collection"""

# Pour la portabilit√©, il est mieux de d√©finir le chemin relatif au script
# Mais je conserve le chemin original pour l'instant.
# L'application Streamlit utilisera un fichier training.csv plac√© dans son dossier.
HOME_DIR = Path("C:/Users/USER/Desktop/ISEP 2/AI/galsenais-fraud-detection-competition20250319-9824-1x0yyob") # Ce chemin est sp√©cifique √† la machine
DATA_TRAIN = HOME_DIR / "training.csv"
# HOME_DIR.mkdir(parents=True, exist_ok=True) # Pas n√©cessaire si le dossier existe d√©j√†
# print(f"Work directory: {HOME_DIR} \nData directory: {DATA_TRAIN}") # Optionnel

# Charger les donn√©es
try:
    df = pd.read_csv(DATA_TRAIN, sep=",")
    logger.info("Donn√©es charg√©es avec succ√®s.")
except FileNotFoundError:
    logger.error(f"Le fichier {DATA_TRAIN} est introuvable. Veuillez v√©rifier le chemin.")
    exit() # Arr√™ter si le fichier n'est pas trouv√©

# ... (Toute la section EDA et feature engineering du notebook original jusqu'√† la mod√©lisation) ...

df['PricingStrategy'] = df['PricingStrategy'].astype('str')

# Cr√©ation des variables d√©riv√©es de AccountId, SubscriptionId, CustomerId
if all(col in df.columns for col in ['CustomerId', 'Amount', 'SubscriptionId', 'TransactionId']):
    df['CustomerId_abs_amount_sum'] = df.groupby('CustomerId')['Amount'].transform(lambda x: x.abs().sum())
    df['SubscriptionId_transaction_count'] = df.groupby('SubscriptionId')['TransactionId'].transform('count')
    df['CustomerId_abs_amount_std'] = df.groupby('CustomerId')['Amount'].transform(lambda x: x.abs().std())
    df['CustomerId_abs_amount_std'] = df['CustomerId_abs_amount_std'].fillna(0)
else:
    logger.warning("Colonnes manquantes pour cr√©er les features CustomerId/SubscriptionId.")

# Cr√©ation des variables d√©riv√©es de TransactionStartTime
if 'Amount' in df.columns:
    df['TransactionType'] = df['Amount'].apply(lambda x: 'Credit' if x < 0 else 'Debit').astype('object')

if 'TransactionStartTime' in df.columns:
    df['TransactionStartTime'] = pd.to_datetime(df['TransactionStartTime'])
    df['TransactionHour'] = df['TransactionStartTime'].dt.hour
    df['TransactionDay'] = df['TransactionStartTime'].dt.day_name(locale='fr_FR')

    def get_moment(hour):
        if 6 <= hour < 13: return 'matin'
        elif 13 <= hour <= 20: return 'apres-midi'
        else: return 'nuit'
    df['MomentOfDay'] = df['TransactionHour'].apply(get_moment)
else:
    logger.warning("Colonne TransactionStartTime manquante.")


# Colonnes √† supprimer (celles du notebook)
cols_to_drop_initial = ['TransactionId', 'BatchId', 'CustomerId','AccountId', 'SubscriptionId',
               'CountryCode', 'CurrencyCode','TransactionStartTime','TransactionHour','ProductCategory']
df.drop(columns=[col for col in cols_to_drop_initial if col in df.columns], inplace=True, errors='ignore')
logger.info(f"Colonnes supprim√©es (initial): {cols_to_drop_initial}")


# Recodage des variables (la logique exacte des listes est cruciale)
# Pour ProductId
if 'ProductId' in df.columns:
    frequencies_product = df['ProductId'].value_counts(normalize=True) * 100
    products_above_12 = frequencies_product[frequencies_product > 12]
    products_list_script = products_above_12.index.tolist() # Liste pour le script
    logger.info(f"ProductId list for recoding (script): {products_list_script}")
    df['ProductId'] = df['ProductId'].apply(lambda x: x if x in products_list_script else 'Other')

# Pour ProviderId
if 'ProviderId' in df.columns:
    frequencies_provider = df['ProviderId'].value_counts(normalize=True) * 100
    provider_above_12 = frequencies_provider[frequencies_provider > 12]
    provider_list_script = provider_above_12.index.tolist() # Liste pour le script
    logger.info(f"ProviderId list for recoding (script): {provider_list_script}")
    df['ProviderId'] = df['ProviderId'].apply(lambda x: x if x in provider_list_script else 'Other')

# Pour ChannelId (liste fixe du notebook)
channel_list_script = ['ChannelId_2','ChannelId_3']
if 'ChannelId' in df.columns:
    df['ChannelId'] = df['ChannelId'].apply(lambda x: x if x in channel_list_script else 'Other')

# Pour PricingStrategy (liste fixe du notebook)
Pricing_list_script = ["2","4"]
if 'PricingStrategy' in df.columns:
    df['PricingStrategy'] = df['PricingStrategy'].astype(str).apply(lambda x: x if x in Pricing_list_script else 'Other')

logger.info("Recodage des variables cat√©gorielles termin√©.")

# Transformations log
if 'Value' in df.columns: df['log_Value'] = np.log1p(df['Value'])
if 'Amount' in df.columns: df['log_abs_Amount'] = np.log1p(df['Amount'].abs())
if 'CustomerId_abs_amount_sum' in df.columns: df['log_CustomerId_abs_amount_sum'] = np.log1p(df['CustomerId_abs_amount_sum'])

# Cr√©ation de Amount_Value_Ecart
if 'Value' in df.columns and 'Amount' in df.columns:
    df['Amount_Value_Ecart'] = df['Value'] - df['Amount'].abs()

# Suppression des colonnes finales avant mod√©lisation (celles du notebook)
cols_to_drop_final = ['Amount', 'Value', 'log_Value', 'log_abs_Amount','CustomerId_abs_amount_sum']
df.drop(columns=[col for col in cols_to_drop_final if col in df.columns], inplace=True, errors='ignore')
logger.info(f"Colonnes supprim√©es (final): {cols_to_drop_final}")


# Identifier les colonnes num√©riques et cat√©gorielles FINALES pour le preprocessor
# Ces listes sont cruciales et doivent correspondre √† ce que le preprocessor utilise.
# Elles sont d√©finies dans la section "Modeling" du notebook.
# Je les red√©finis ici pour clart√©, en s'assurant qu'elles existent dans le df final.
df_final_features = df.drop('FraudResult', axis=1, errors='ignore') # X pour la mod√©lisation

numeric_columns_model = df_final_features.select_dtypes(include=['float64', 'int64']).columns.tolist()
categorical_columns_model = df_final_features.select_dtypes(include="object").columns.tolist()

logger.info(f"Colonnes num√©riques finales pour le mod√®le: {numeric_columns_model}")
logger.info(f"Colonnes cat√©gorielles finales pour le mod√®le: {categorical_columns_model}")


"""# Modeling

## R√©gression logistique
"""
# ----------------------------
# 1. S√©paration des variables (apr√®s tout le feature engineering)
# ----------------------------
if 'FraudResult' not in df.columns:
    logger.error("La colonne cible 'FraudResult' est manquante avant la mod√©lisation.")
    exit()

X = df.drop('FraudResult', axis=1)
y = df['FraudResult']


X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)
logger.info(f"Dimensions X_train: {X_train.shape}, X_val: {X_val.shape}")


# ===> AJOUT IMPORTANT : Sauvegarde des noms des colonnes brutes (celles de X_train) <===
# Ces colonnes sont celles apr√®s TOUT le feature engineering manuel,
# et ce sont celles que le preprocessor du pipeline va recevoir.
raw_training_columns_for_pipeline = X_train.columns.tolist()
try:
    with open('training_raw_features.dill', 'wb') as f: # Nom du fichier pour les colonnes
        dill.dump(raw_training_columns_for_pipeline, f)
    logger.info(f"Liste des colonnes (apr√®s FE manuel) pour le pipeline sauvegard√©e sous : training_raw_features_friend.dill")
    logger.info(f"Nombre de colonnes sauvegard√©es : {len(raw_training_columns_for_pipeline)}")
    # logger.debug(f"Colonnes : {raw_training_columns_for_pipeline}") # Pour d√©bug
except Exception as e:
    logger.error(f"ERREUR lors de la sauvegarde des colonnes pour le pipeline : {e}")
# ===> FIN DE L'AJOUT <===


# ----------------------------
# 2. Pr√©traitement (D√©finition du preprocessor)
# ----------------------------
# Utiliser les listes de colonnes d√©termin√©es juste avant pour le ColumnTransformer
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_columns_model), # numeric_columns_model
    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_columns_model) # categorical_columns_model
])
logger.info("Preprocessor d√©fini.")
# logger.debug(f"Preprocessor numeric columns: {numeric_columns_model}")
# logger.debug(f"Preprocessor categorical columns: {categorical_columns_model}")

# ... (Le reste du code de mod√©lisation, y compris la baseline, le tuning, etc.) ...
# Il est crucial que `numeric_columns` et `categorical_columns` utilis√©s dans
# `preprocessor` correspondent bien √† `numeric_columns_model` et `categorical_columns_model`
# Ici, le code du notebook original r√©utilise `numeric_columns` et `categorical_columns`
# qui ont √©t√© d√©finis plus haut. Il faut s'assurer de leur coh√©rence.
# Dans le notebook, `numeric_columns` est red√©fini plusieurs fois. La derni√®re d√©finition avant
# la mod√©lisation est :
# numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
# numeric_columns = [col for col in numeric_columns if col != 'FraudResult']
# C'est ce que j'ai utilis√© pour `numeric_columns_model`.
# De m√™me pour `categorical_columns_model`.

# ----------------------------
# Baseline (mod√®le par d√©faut) - pour v√©rifier que preprocessor est bien d√©fini
# ----------------------------
logger.info("üìå Baseline : R√©gression Logistique sans tuning ni sampling")

baseline_pipeline = imb_Pipeline([ # Utiliser imb_Pipeline pour la coh√©rence
    ('preproc', preprocessor),
    ('clf', LogisticRegression(random_state=42, solver='lbfgs', max_iter=1000)) # Augmenter max_iter
])

try:
    baseline_pipeline.fit(X_train, y_train)
    y_pred_baseline = baseline_pipeline.predict(X_val)
    y_proba_baseline = baseline_pipeline.predict_proba(X_val)[:, 1]

    logger.info("‚û°Ô∏è Performance du mod√®le baseline :")
    logger.info(f"Accuracy  : {accuracy_score(y_val, y_pred_baseline):.4f}")
    logger.info(f"Pr√©cision : {precision_score(y_val, y_pred_baseline, zero_division=0):.4f}")
    logger.info(f"Rappel    : {recall_score(y_val, y_pred_baseline):.4f}")
    logger.info(f"F1-score  : {f1_score(y_val, y_pred_baseline):.4f}")
    logger.info(f"ROC AUC   : {roc_auc_score(y_val, y_proba_baseline):.4f}")
except Exception as e:
    logger.error(f"Erreur lors de l'entra√Ænement ou de l'√©valuation du pipeline baseline: {e}")
    logger.error("V√©rifiez la coh√©rence des `numeric_columns_model` et `categorical_columns_model` avec l'√©tat de `X_train`.")


# ... (Tuning and sampling with regression logistique - comme dans le notebook) ...
logger.info("\n--- Tuning et Sampling avec R√©gression Logistique ---")
# Param√®tres de base du classifieur
param_grid = {
    'clf__penalty': ['l2'],
    'clf__C': [0.1, 10], # R√©duire pour aller plus vite, le notebook a [0.1, 1, 10]
    'clf__solver': ['lbfgs'], # Le notebook a ['liblinear', 'lbfgs']
    'clf__max_iter': [1000, 6000] # Le notebook a [1000, 2000, 6000]
}
# Param√®tres avec sur√©chantillonnage SMOTE
param_grid_smote = param_grid.copy()
param_grid_smote.update({
    'smote__sampling_strategy': [0.25, 0.5]
})
# Param√®tres avec sous-√©chantillonnage
param_grid_under = param_grid.copy()
param_grid_under.update({
    'under__sampling_strategy': [0.25, 0.5]
})
pipelines = {
    "Original": imb_Pipeline([
        ('preproc', preprocessor),
        ('clf', LogisticRegression(random_state=42)) # Mettre random_state
    ]),
    "SMOTE": imb_Pipeline([
        ('preproc', preprocessor),
        ('smote', SMOTE(random_state=42)),
        ('clf', LogisticRegression(random_state=42))
    ]),
    "UnderSampling": imb_Pipeline([
        ('preproc', preprocessor),
        ('under', RandomUnderSampler(random_state=42)),
        ('clf', LogisticRegression(random_state=42))
    ]),
    "Pond√©ration": imb_Pipeline([
        ('preproc', preprocessor),
        ('clf', LogisticRegression(class_weight='balanced', random_state=42))
    ])
}
resultats = []
best_model_overall = None
best_f1_overall = -1

for methode, pipeline in pipelines.items():
    logger.info(f"\nüîç M√©thode : {methode}")
    current_param_grid = param_grid
    if "SMOTE" in methode: current_param_grid = param_grid_smote
    elif "UnderSampling" in methode: current_param_grid = param_grid_under

    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42) # n_splits=5 pour aller plus vite, le notebook a 9
    grid = GridSearchCV(pipeline, current_param_grid, cv=cv, scoring='f1', n_jobs=-1, error_score='raise', verbose=1) # verbose=1
    
    try:
        grid.fit(X_train, y_train)
        best_model_current_methode = grid.best_estimator_
        y_pred = best_model_current_methode.predict(X_val)
        y_proba = best_model_current_methode.predict_proba(X_val)[:, 1]
        current_f1 = f1_score(y_val, y_pred)

        resultats.append({
            'M√©thode': methode,
            'Accuracy': accuracy_score(y_val, y_pred),
            'Pr√©cision': precision_score(y_val, y_pred, zero_division=0),
            'Rappel': recall_score(y_val, y_pred),
            'F1-score': current_f1,
            'ROC AUC': roc_auc_score(y_val, y_proba),
            'Best Params': grid.best_params_
        })
        if current_f1 > best_f1_overall:
            best_f1_overall = current_f1
            best_model_overall = best_model_current_methode # Sauvegarder le meilleur mod√®le bas√© sur F1
            logger.info(f"Nouveau meilleur mod√®le trouv√© avec {methode}, F1-score: {current_f1:.4f}")

    except Exception as e:
        logger.error(f"Erreur pendant GridSearchCV pour m√©thode {methode}: {e}")
        resultats.append({
            'M√©thode': methode, 'F1-score': -1, 'Error': str(e)
        })


df_resultats = pd.DataFrame(resultats)
df_resultats = df_resultats.sort_values(by='F1-score', ascending=False).reset_index(drop=True)
logger.info("\nüìä R√©sum√© des performances pour r√©gression logistique:")
print(df_resultats[['M√©thode', 'F1-score', 'ROC AUC', 'Best Params']].to_string()) # Afficher plus proprement

# R√©cup√©rer le pipeline optimal pour r√©gression logistique
# Le notebook choisit 'UnderSampling' mais le code ci-dessus prend le meilleur F1 global.
# Je vais suivre la logique du meilleur F1 global. Si aucun mod√®le n'a fonctionn√©, best_model_overall sera None.
if best_model_overall is not None:
    logger.info(f"\nLe meilleur pipeline global est bas√© sur le F1-score max: {best_f1_overall:.4f}")
    best_pipeline_regression_logistique = best_model_overall # C'est d√©j√† le pipeline complet
else:
    # Fallback si GridSearchCV a √©chou√© pour toutes les m√©thodes,
    # ou si on veut explicitement celui du notebook.
    # Pour l'instant, on va supposer que best_model_overall est le bon.
    # il faudra ajuster cette logique.
    logger.warning("Aucun best_model_overall trouv√©, tentative de recr√©er le mod√®le 'UnderSampling' du notebook si pr√©sent.")
    if not df_resultats.empty and 'UnderSampling' in df_resultats['M√©thode'].values:
        under_sampling_results = df_resultats[df_resultats['M√©thode'] == 'UnderSampling'].iloc[0]
        if pd.notna(under_sampling_results.get('Best Params')):
            best_params_under = under_sampling_results['Best Params']
            best_pipeline_regression_logistique = imb_Pipeline([
                ('preproc', preprocessor),
                ('under', RandomUnderSampler(sampling_strategy=best_params_under['under__sampling_strategy'], random_state=42)),
                ('clf', LogisticRegression(
                    penalty=best_params_under['clf__penalty'],
                    C=best_params_under['clf__C'],
                    solver=best_params_under['clf__solver'],
                    max_iter=best_params_under['clf__max_iter'],
                    random_state=42
                ))
            ])
            logger.info("Recr√©ation du pipeline 'UnderSampling' avec les param√®tres trouv√©s.")
            best_pipeline_regression_logistique.fit(X_train, y_train) # R√©-entra√Æner
        else:
            logger.error("Impossible de recr√©er le pipeline 'UnderSampling', param√®tres non trouv√©s ou erreur.")
            best_pipeline_regression_logistique = None # Pour √©viter une erreur plus loin
    else:
        logger.error("M√©thode 'UnderSampling' non trouv√©e dans les r√©sultats ou resultats vides.")
        best_pipeline_regression_logistique = None


# Enregistrer le meilleur mod√®le avec dill (s'il existe)
if best_pipeline_regression_logistique is not None:
    MODEL_SAVE_PATH = 'best_Regression_logistique.dill' # Correspond au nom de fichier dans le notebook
    try:
        with open(MODEL_SAVE_PATH, 'wb') as f:
            dill.dump(best_pipeline_regression_logistique, f)
        logger.info(f"Meilleur mod√®le de r√©gression logistique sauvegard√© sous : {MODEL_SAVE_PATH}")

        # Tester le chargement (optionnel mais bonne pratique)
        with open(MODEL_SAVE_PATH, 'rb') as f:
            loaded_model_test = dill.load(f)
        y_pred_test_load = loaded_model_test.predict(X_val.head()) # Pr√©dire sur quelques lignes
        logger.info(f"Test de pr√©diction du mod√®le charg√© (premi√®res 5 lignes de X_val): {y_pred_test_load}")
    except Exception as e:
        logger.error(f"Erreur lors de la sauvegarde ou du test de chargement du mod√®le : {e}")
else:
    logger.error("Aucun pipeline de r√©gression logistique final √† sauvegarder.")


# ... (La section KNN du notebook pourrait suivre ici si n√©cessaire) ...
logger.info("Fin du script de modification pour sauvegarde.")